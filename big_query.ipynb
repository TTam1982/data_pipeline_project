{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "SOURCE_CSV_FILE = os.path.abspath(\"./datasets/rangalamahesh_bank_churn.csv\")\n",
    "# Khởi tạo Spark session\n",
    "spark = SparkSession.builder.appName(\"ChurnDataSQL\").getOrCreate()\n",
    "\n",
    "# Đọc dữ liệu từ tệp CSV\n",
    "df = spark.read.csv(SOURCE_CSV_FILE, header=True, inferSchema=True)\n",
    "\n",
    "# Hiển thị schema của dữ liệu\n",
    "df.printSchema()\n",
    "\n",
    "# Tạo bảng tạm thời cho dữ liệu để thực hiện các truy vấn SQL\n",
    "df.createOrReplaceTempView(\"churn_data\")\n",
    "\n",
    "print(\"1. Tính toán tỷ lệ giữ lại khách hàng theo quốc gia và giới tính\")\n",
    "\n",
    "retention_rate_by_country_gender = spark.sql(\"\"\"\n",
    "    SELECT Geography, Gender, \n",
    "           SUM(CASE WHEN IsActiveMember = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS RetentionRate\n",
    "    FROM churn_data\n",
    "    GROUP BY Geography, Gender\n",
    "    ORDER BY RetentionRate DESC\n",
    "\"\"\")\n",
    "retention_rate_by_country_gender.show()\n",
    "\n",
    "print(\"2. Tìm 5 khách hàng có số dư lớn nhất trong mỗi quốc gia\")\n",
    "top_balance_by_country = spark.sql(\"\"\"\n",
    "    SELECT CustomerId, Geography, Balance\n",
    "    FROM (\n",
    "        SELECT CustomerId, Geography, Balance,\n",
    "               ROW_NUMBER() OVER (PARTITION BY Geography ORDER BY Balance DESC) AS rank\n",
    "        FROM churn_data\n",
    "    ) ranked\n",
    "    WHERE rank <= 5\n",
    "    ORDER BY Geography, rank\n",
    "\"\"\")\n",
    "top_balance_by_country.show()\n",
    "\n",
    "print(\"3. Tính toán số dư trung bình và tổng số sản phẩm cho mỗi nhóm tuổi (Age Group)\")\n",
    "balance_and_products_by_age_group = spark.sql(\"\"\"\n",
    "    SELECT AgeGroup, \n",
    "           AVG(Balance) AS AvgBalance, \n",
    "           SUM(NumOfProducts) AS TotalProducts\n",
    "    FROM (\n",
    "        SELECT *,\n",
    "               CASE \n",
    "                   WHEN Age < 25 THEN 'Under 25'\n",
    "                   WHEN Age BETWEEN 25 AND 34 THEN '25-34'\n",
    "                   WHEN Age BETWEEN 35 AND 44 THEN '35-44'\n",
    "                   WHEN Age BETWEEN 45 AND 54 THEN '45-54'\n",
    "                   ELSE '55+' \n",
    "               END AS AgeGroup\n",
    "        FROM churn_data\n",
    "    ) grouped\n",
    "    GROUP BY AgeGroup\n",
    "    ORDER BY AgeGroup\n",
    "\"\"\")\n",
    "balance_and_products_by_age_group.show()\n",
    "\n",
    "print(\"4. Tính toán tổng số dư và số dư trung bình của các khách hàng đã hoạt động trong hơn 5 năm và có thẻ tín dụng\")\n",
    "active_customers_balance = spark.sql(\"\"\"\n",
    "    SELECT SUM(Balance) AS TotalBalance, \n",
    "           AVG(Balance) AS AvgBalance\n",
    "    FROM churn_data\n",
    "    WHERE Tenure > 5 \n",
    "      AND HasCrCard = 1\n",
    "\"\"\")\n",
    "active_customers_balance.show()\n",
    "\n",
    "print(\"5. Tìm các khách hàng có mức lương ước tính bất thường so với số dư tài khoản bằng cách sử dụng z-score\")\n",
    "from pyspark.sql.functions import mean, stddev\n",
    "\n",
    "# Tính toán mean và stddev của Balance và EstimatedSalary\n",
    "stats = df.select(mean(\"Balance\").alias(\"mean_balance\"),\n",
    "                  stddev(\"Balance\").alias(\"std_balance\"),\n",
    "                  mean(\"EstimatedSalary\").alias(\"mean_salary\"),\n",
    "                  stddev(\"EstimatedSalary\").alias(\"std_salary\")).collect()\n",
    "\n",
    "mean_balance = stats[0][\"mean_balance\"]\n",
    "std_balance = stats[0][\"std_balance\"]\n",
    "mean_salary = stats[0][\"mean_salary\"]\n",
    "std_salary = stats[0][\"std_salary\"]\n",
    "\n",
    "# Thêm cột z-score cho Balance và EstimatedSalary\n",
    "df = df.withColumn(\"z_score_balance\", (df.Balance - mean_balance) / std_balance)\n",
    "df = df.withColumn(\"z_score_salary\", (df.EstimatedSalary - mean_salary) / std_salary)\n",
    "\n",
    "# Tạo bảng tạm thời mới cho dữ liệu đã được thêm z-score\n",
    "df.createOrReplaceTempView(\"churn_data_with_z\")\n",
    "\n",
    "# Truy vấn các khách hàng có z-score của EstimatedSalary cao hơn ngưỡng nhất định (ví dụ: 2) so với z-score của Balance\n",
    "anomalous_customers = spark.sql(\"\"\"\n",
    "    SELECT CustomerId, Balance, EstimatedSalary, z_score_balance, z_score_salary\n",
    "    FROM churn_data_with_z\n",
    "    WHERE ABS(z_score_salary - z_score_balance) > 2\n",
    "    ORDER BY ABS(z_score_salary - z_score_balance) DESC\n",
    "\"\"\")\n",
    "anomalous_customers.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
